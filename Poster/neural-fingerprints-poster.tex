%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% From a template maintained at https://github.com/jamesrobertlloyd/cbl-tikz-poster
%
% Code near the top should be fairly standard and not need to be changed
%  - except for the document class
% Code lower down is more likely to be customised
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass[landscape,a0b,final,a4resizeable]{include/a0poster}
\usepackage[utf8]{inputenc}

\usepackage{multicol}
\usepackage{color}
\usepackage{morefloats}
\usepackage[pdftex]{graphicx}
\usepackage{rotating}
\usepackage{amsmath, amsthm, amssymb, bm}
\usepackage{array}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{hyperref}


\usepackage{include/picins}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric,arrows,chains,matrix,positioning,scopes,calc}
\tikzstyle{mybox} = [draw=white, rectangle]
\definecolor{darkblue}{rgb}{0,0.08,0.45}
\definecolor{blue}{rgb}{0,0,1}

\usepackage{dsfont}

\input{include/jlposter.tex}

\input{include/preamble.sty}
\newcommand{\vv}{\mathbf{v}}

\begin{document}
\begin{poster} 

% Potentially add some space at the top of the poster
\vspace{0\baselineskip}


%%% Header
\begin{center}
\begin{pcolumn}{0.99}

\newcommand{\logowidth}{0.11\textwidth}

\pbox{0.99\textwidth}{}{linewidth=2mm,framearc=0.3,linecolor=camdarkblue,fillstyle=gradient,gradangle=0,gradbegin=white,gradend=white,gradmidpoint=1.0,framesep=1em}{
%
%%% Cambridge Logo
\begin{minipage}[c]{\logowidth}
  \begin{center}
    \includegraphics[width=7cm]{badges/cambridgecrest}
  \end{center}
\end{minipage}
%
%%% Title
\begin{minipage}[c][9cm][c]{0.76\textwidth}
  \begin{center}
    {\sffamily \VeryHuge \textbf{Auto-Encoding Variational Bayes}}\\[10mm]
    {\huge\sffamily \Huge Pawe≈Ç Budzianowski, ,   \\[7.5mm]
    %\texttt{\{ti242, dkd23, zoubin\}@cam.ac.uk}
    }
  \end{center}
\end{minipage}
%
%
% Harvard logo
\begin{minipage}[c]{\logowidth}
  \begin{flushright}
    \includegraphics[width=15cm, clip]{badges/camtext}
  \end{flushright}
\end{minipage}
%
}
\end{pcolumn}
\end{center}

\vspace*{3cm}

\Large


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Beginning of Document
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{multicols}{3}

\mysection{How to do regression on graphs?}

%\vspace{-0.5in}

\begin{tabular}{cc}
\begin{minipage}[c]{0.45\columnwidth}
\begin{itemize}
  \item Input can be any size or shape
  \item Hard to turn into fixed-length vector
  \item In our case, graphs represent molecules
  \item Applications to photovoltaics, organic LEDS, flow batteries and pharmaceuticals
\end{itemize}
\end{minipage} & 
\begin{minipage}[c]{0.55\columnwidth}
%\includegraphics[width=\columnwidth]{../talks/talkfigs/learning_curves_3.pdf}
\centerline{\includegraphics[width=1.0\columnwidth, clip, trim=4mm 0mm 4mm 4mm]{figures/how-fingerprints.png}}
\end{minipage}
\end{tabular}

%\vspace{-0.5in}

\vspace{1.5in}

\mysection{Circular fingerprints}

%Also called Morgan fingerprints, or ECFP

\vspace{0.5in}

\begin{tabular}{cc}
\begin{minipage}[c]{0.5\columnwidth}
\begin{itemize}
  \item Maps variable-sized molecular graph to fixed-length binary vector
  %\item Does this by hashing self with neighbors iteratively
  \item Binary features indicate presence of substructures
\end{itemize}

\vspace{0.5in}

Can be efficiently computed using local operations:

\begin{itemize}
  \item At each layer, hash the features of each atom and its neighbors/bonds
  \item More layers correspond to increasing radius of substructures
  \item Interpret each hash as integer and set that entry to one
\end{itemize}
\end{minipage} & 
\begin{minipage}[c]{0.5\columnwidth}
%\includegraphics[width=\columnwidth]{../talks/talkfigs/learning_curves_3.pdf}
\centerline{\includegraphics[width=0.9\columnwidth, clip, trim=4mm 12mm 4mm 4mm]{figures/fig_1}}
\end{minipage}
\end{tabular}

\vspace{0.5in}

Was state-of-the-art for large-scale regression and classification.



\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\mysection{Learning Curves - la vs lb}

Comparison of learning

\vspace{0.5em}

\begin{center}
\includegraphics[width=.8\columnwidth]{../res/mnist_LAvsLB}
\end{center}

\vspace{0.5em}

\mysection{Visualisation of learned manifolds}

It is possible to observe what the encoder learnt during training if we choose a low-dimensional latent space e.g. $2D$. The linearly spaced grid of coordinates over the unit square is mapped through the inverse CDF of the Gaussian (our prior for the latent space is Gaussian) to obtain the value of $\mathbf{z}$. Then, we plotted the output of our decoder $p_{\mathbf{\theta}} (\mathbf{x}| \mathbf{z})$ with the estimated parameters $\mathbf{\theta}$.

\vspace{0.5em}

\begin{tabular}{cc}
\begin{minipage}[c]{0.48\columnwidth}
\includegraphics[width=.8\columnwidth]{../freyFaces/MNIST}
\end{minipage} & 
\begin{minipage}[c]{0.48\columnwidth}
\begin{center}
\vspace{0.5cm}
\includegraphics[width=.7\columnwidth]{../freyFaces/FREY}
\end{center}
\end{minipage}
\end{tabular}

\vspace{0.5em}

\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\mysection{Full VB}

Large random weights give similar behavior to circular fingeprints:

\vspace{0.5em}

Small random weights already much better than circular fingerprints!
Can do even better by optimizing for given task.

\vspace{1in}

\mysection{Architecture experiments}

We examined various changes to the original architecture of the auto-encoder to test the robustness and flexibility of the model which lead to improvement in terms of optimising the lower bound and computational efficiency.

\begin{tabular}{cc}
\begin{minipage}[c]{0.25\columnwidth}
\begin{itemize}
\item Different activation functions.
\end{itemize}
\end{minipage} & 
\begin{minipage}[c]{0.75\columnwidth}
\includegraphics[width=1.0\columnwidth, clip, trim=4mm 0mm 4mm 4mm]{../res/mnist_activations}
\end{minipage}
\end{tabular}

\vspace{0.5em}

\begin{tabular}{cc}
\begin{minipage}[c]{0.25\columnwidth}
\begin{itemize}
\item Increasing the depth of the encoder.
\end{itemize}
\end{minipage} & 
\begin{minipage}[c]{0.75\columnwidth}
\includegraphics[width=1.0\columnwidth, clip, trim=4mm 0mm 4mm 4mm]{../res/mnist_depth}
\end{minipage}
\end{tabular}

\vspace{0.5em}

\mysection{Future works}

\begin{itemize}
\item Scheduled training of VAEB $[2]$.
\item
\item 
\end{itemize}

\vspace{0.5em}

\mysection{References}
\begin{enumerate}
\item Kingma, D. P., and  Welling M., "Auto-encoding variational bayes." arXiv preprint arXiv:1312.6114 (2013).
\item Geras, K. J., and Sutton C., "Scheduled denoising autoencoders." arXiv preprint arXiv:1406.3269 (2014).
\end{enumerate}

\end{multicols}
\end{poster}

\end{document}

